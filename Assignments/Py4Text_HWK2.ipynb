{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Py4Text_HWK2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cristina-ramos/class_P4T/blob/main/Assignments/Py4Text_HWK2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXcSiNwtqxlw"
      },
      "source": [
        "> The texts I've chosen for my corpus are all novels or short stories under the children's literature genre. They were obtained from Project Gutenberg's children's literature bookshelf: http://www.gutenberg.org/ebooks/bookshelf/20\n",
        "\n",
        "The texts are:\n",
        "> 1. Alice's Adventures in Wonderland by Lewis Carroll\n",
        "2. Anne of Green Gables by Lucy Maud Montgomery\n",
        "3. Black Beauty by Anna Sewell\n",
        "4. Jack and Jill by Louisa May Alcott\n",
        "5. The Jungle Book by Rudyard Kipling\n",
        "6. The Wonderful Wizard of Oz by L. Frank Baum\n",
        "7. Peter Pan by James M. Barrie\n",
        "8. The Secret Garden by Frances Hodgson Burnett\n",
        "9. Treasure Island by Robert Louis Stevenson\n",
        "10. The Velveteen Rabbit by Margery Williams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjcZmcZmk1t6"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "corpus_root = r\"/content/sample_data/literature\"\n",
        "corpus = PlaintextCorpusReader(corpus_root, '.*txt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MDsNZgSzd5W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "36d25edd-41db-4948-cfb6-ffad99245ed7"
      },
      "source": [
        "#Exploring the corpus now:\n",
        "print(corpus.fileids())\n",
        "total_words = len(corpus.words())\n",
        "print(\"The total words in the children's literature corpus are:\", total_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['alice.txt', 'anne.txt', 'blackbeauty.txt', 'jack&jill.txt', 'jungle.txt', 'oz.txt', 'peter.txt', 'secret_garden.txt', 'treasure.txt', 'velveteen.txt']\n",
            "The total words in the children's literature corpus are: 742021\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7W4QK94zqrE"
      },
      "source": [
        "> How long is each text?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4bp419mzs43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "167333b0-57cf-40b0-e171-90fda3bd4cce"
      },
      "source": [
        "alice_words = len(corpus.words(fileids='alice.txt'))\n",
        "print(\"The total number of words in Alice's Adventures in Wonderland are:\", alice_words)\n",
        "anne_words = len(corpus.words(fileids='anne.txt'))\n",
        "print(\"The total number of words in Anne of Green Gables are:\", anne_words)\n",
        "bb_words = len(corpus.words(fileids='blackbeauty.txt'))\n",
        "print(\"The total number of words in Black Beauty are:\", bb_words)\n",
        "jj_words = len(corpus.words(fileids='jack&jill.txt'))\n",
        "print(\"The total number of words in Jack and Jill are:\", jj_words)\n",
        "jungle_words = len(corpus.words(fileids='jungle.txt'))\n",
        "print(\"The total number of words in The Jungle Book are:\", jungle_words)\n",
        "oz_words = len(corpus.words(fileids='oz.txt'))\n",
        "print(\"The total number of words in The Wonderful Wizard of Oz are:\", oz_words)\n",
        "peter_words = len(corpus.words(fileids='peter.txt'))\n",
        "print(\"The total number of words in Peter Pan are:\", peter_words)\n",
        "sg_words = len(corpus.words(fileids='secret_garden.txt'))\n",
        "print(\"The total number of words in The Secret Garden are:\", sg_words)\n",
        "treasure_words = len(corpus.words(fileids='treasure.txt'))\n",
        "print(\"The total number of words in Treasure Island are:\", treasure_words)\n",
        "rabbit_words = len(corpus.words(fileids='velveteen.txt'))\n",
        "print(\"The total number of words in The Velveteen Rabbit are:\", rabbit_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The total number of words in Alice's Adventures in Wonderland are: 39164\n",
            "The total number of words in Anne of Green Gables are: 131023\n",
            "The total number of words in Black Beauty are: 75083\n",
            "The total number of words in Jack and Jill are: 116750\n",
            "The total number of words in The Jungle Book are: 65942\n",
            "The total number of words in The Wonderful Wizard of Oz are: 50339\n",
            "The total number of words in Peter Pan are: 62476\n",
            "The total number of words in The Secret Garden are: 103179\n",
            "The total number of words in Treasure Island are: 89328\n",
            "The total number of words in The Velveteen Rabbit are: 8737\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u27R1DWi_PS3"
      },
      "source": [
        "> What is the average length of each text?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viivT6q__Nzb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "aa9f3862-9b0a-454a-d994-fcfc049fa6b6"
      },
      "source": [
        "nltk.download('punkt')\n",
        "for fileid in corpus.fileids():\n",
        "  num_words = len(corpus.words(fileid))\n",
        "  num_chars = len(corpus.raw(fileid))\n",
        "  print(\"Average word length is:\", round(num_chars/num_words), \"for\", fileid)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "Average word length is: 5 for alice.txt\n",
            "Average word length is: 5 for anne.txt\n",
            "Average word length is: 4 for blackbeauty.txt\n",
            "Average word length is: 5 for jack&jill.txt\n",
            "Average word length is: 5 for jungle.txt\n",
            "Average word length is: 5 for oz.txt\n",
            "Average word length is: 5 for peter.txt\n",
            "Average word length is: 4 for secret_garden.txt\n",
            "Average word length is: 4 for treasure.txt\n",
            "Average word length is: 5 for velveteen.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrX1Tq1DBCR4"
      },
      "source": [
        "> 20 most common words in the corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Pcg8BUBFUs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f7c59932-0593-4cd9-9861-46949522d8ae"
      },
      "source": [
        "from nltk import FreqDist\n",
        "corpus_vocab = corpus.words()\n",
        "freq_corpus = FreqDist(corpus_vocab)\n",
        "print(\"These are the 20 most common words in the corpus:\", freq_corpus.most_common(20))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are the 20 most common words in the corpus: [(',', 38005), ('the', 29009), ('.', 27924), ('and', 22261), ('to', 15694), ('a', 13349), ('I', 12214), ('of', 11904), ('“', 10238), ('was', 8595), ('in', 7960), ('’', 7757), ('it', 7310), ('he', 6791), ('that', 6443), ('you', 6195), (\"'\", 5627), ('as', 5211), ('she', 4997), ('with', 4877)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zLiGOvvvB6Xs"
      },
      "source": [
        "> 20 most common bigrams in the corpus?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gMFl99aB5-8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "d452e619-1567-42db-acfa-c9afc3ae6332"
      },
      "source": [
        "from nltk import bigrams\n",
        "list(nltk.bigrams(freq_corpus.most_common(20)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[((',', 38005), ('the', 29009)),\n",
              " (('the', 29009), ('.', 27924)),\n",
              " (('.', 27924), ('and', 22261)),\n",
              " (('and', 22261), ('to', 15694)),\n",
              " (('to', 15694), ('a', 13349)),\n",
              " (('a', 13349), ('I', 12214)),\n",
              " (('I', 12214), ('of', 11904)),\n",
              " (('of', 11904), ('“', 10238)),\n",
              " (('“', 10238), ('was', 8595)),\n",
              " (('was', 8595), ('in', 7960)),\n",
              " (('in', 7960), ('’', 7757)),\n",
              " (('’', 7757), ('it', 7310)),\n",
              " (('it', 7310), ('he', 6791)),\n",
              " (('he', 6791), ('that', 6443)),\n",
              " (('that', 6443), ('you', 6195)),\n",
              " (('you', 6195), (\"'\", 5627)),\n",
              " ((\"'\", 5627), ('as', 5211)),\n",
              " (('as', 5211), ('she', 4997)),\n",
              " (('she', 4997), ('with', 4877))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "feVSU7a1Js5P"
      },
      "source": [
        ">20 most common words and bigrams after removing stopwords and punctuation?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6jJGhU5NsUT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b66d9e07-a3ba-4a05-c355-ddd6fbd9d711"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "# nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "new_vocab = []\n",
        "for word in corpus_vocab:\n",
        "  if word not in stop_words and word not in string.punctuation:\n",
        "    new_vocab.append(word)\n",
        "\n",
        "print(\"Total length in orginal corpus:\", len(corpus_vocab))\n",
        "print(\"Total length in corpus with stopwords and punctuation removed:\", len(new_vocab))\n",
        "print(\"Number of stopwords removed is:\", len(corpus_vocab) - len(new_vocab))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total length in orginal corpus: 742021\n",
            "Total length in corpus with stopwords and punctuation removed: 361084\n",
            "Number of stopwords removed is: 380937\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwfcH6YIP_XW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7ae8f4c1-37fc-481f-bc22-6145902a3525"
      },
      "source": [
        "new_freq = FreqDist(new_vocab)\n",
        "print(\"These are the 20 most common words in the corpus with stopwords and punctuation removed:\", new_freq.most_common(20))\n",
        "#still some punctuation not included in my removal method but still a better result than before"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "These are the 20 most common words in the corpus with stopwords and punctuation removed: [('I', 12214), ('“', 10238), ('’', 7757), ('said', 4247), (',”', 3710), ('.”', 3251), ('one', 2091), ('The', 2074), ('would', 1747), ('little', 1679), ('--', 1667), ('like', 1632), ('could', 1531), ('It', 1530), ('?”', 1513), ('He', 1458), ('Anne', 1221), ('see', 1204), ('good', 1175), ('!”', 1158)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2a-YjkbTsH-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "4329441f-b0d4-4e10-de8a-3e30c7a561b6"
      },
      "source": [
        "list(nltk.bigrams(new_freq.most_common(20)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('I', 12214), ('“', 10238)),\n",
              " (('“', 10238), ('’', 7757)),\n",
              " (('’', 7757), ('said', 4247)),\n",
              " (('said', 4247), (',”', 3710)),\n",
              " ((',”', 3710), ('.”', 3251)),\n",
              " (('.”', 3251), ('one', 2091)),\n",
              " (('one', 2091), ('The', 2074)),\n",
              " (('The', 2074), ('would', 1747)),\n",
              " (('would', 1747), ('little', 1679)),\n",
              " (('little', 1679), ('--', 1667)),\n",
              " (('--', 1667), ('like', 1632)),\n",
              " (('like', 1632), ('could', 1531)),\n",
              " (('could', 1531), ('It', 1530)),\n",
              " (('It', 1530), ('?”', 1513)),\n",
              " (('?”', 1513), ('He', 1458)),\n",
              " (('He', 1458), ('Anne', 1221)),\n",
              " (('Anne', 1221), ('see', 1204)),\n",
              " (('see', 1204), ('good', 1175)),\n",
              " (('good', 1175), ('!”', 1158))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNbb5hN4dQi3"
      },
      "source": [
        ">Writing these results to a new file:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRTyCr4tUBdp"
      },
      "source": [
        "new_file = open('submit_file.txt', 'w')\n",
        "\n",
        "new_file.writelines([\"These are the 20 most common words in the corpus with stopwords and punctuation removed:\", str(new_freq.most_common(20))])\n",
        "new_file.writelines([\"\\n\"\"These are the 20 most frequent bigrams in the corpus with stopwords and punctuation removed:\", str(list(nltk.bigrams(new_freq.most_common(20))))])\n",
        "\n",
        "new_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}